NCBF Training Report
============================================================

Training Duration: 20 epochs
Final Training Loss: 0.767662
Final Validation Loss: 0.000369
Best Validation Loss: 0.000000

Configuration:
  input_dim: 3
  hidden_dims: [256, 256, 128, 64, 32]
  activation: relu
  output_dim: 1
  learning_rate: 0.005
  weight_decay: 0.0001
  dropout_rate: 0.3
  batch_size: 1024
  max_epochs: 20
  use_batch_norm: True
  use_residual: False
  use_dropout: True
  classification_weight: 5.0
  barrier_weight: 2.0
  regularization_weight: 0.5
  margin: 0.5
  min_unsafe_ratio: 0.3
  obstacle_focus_ratio: 0.3
  checkpoint_dir: /home/chengrui/wk/NCBFquickDemo/work/ncbf/weights/conservative_test_final
  model_name: ncbf_model
  save_frequency: 25
  validation_split: 0.2
  early_stopping_patience: 50
  optimizer: adam
  scheduler: step
  scheduler_step_size: 200
  scheduler_gamma: 0.1
  device: auto
  num_workers: 8
  pin_memory: True
  mixed_precision: True
  log_frequency: 10
  plot_frequency: 25
  save_best_only: True
  show_training_plots: True
  contour_resolution: 150
  contour_levels: 20
  evaluation_theta: 0.0
  conservative_weight: 0.5
  temperature: 0.1
  num_random_controls: 10
  enable_pretraining: False
  pretrain_epochs: 0
  pretrain_lr: 0.001

Final Model Statistics:
  architecture: [3, 256, 256, 128, 64, 32, 1]
  activation: relu
  total_parameters: 111553
  trainable_parameters: 111553
  model_size_mb: 0.4255409240722656

Conservative Training Statistics:
  Conservative weight: 0.5
  Temperature: 0.1
  Random controls: 10
  Pretraining enabled: False
